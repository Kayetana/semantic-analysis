{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8006b892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      ", Dave, watched, as, the, forest, burned, up, on, the, hill, ,, \n",
      ", only, a, few, miles, from, his, house, ., The, car, had, \n",
      ", been, hastily, packed, and, Marta, was, inside, trying, to, round, \n",
      ", up, the, last, of, the, pets, ., \", Where, could, she, be, ?, \", he, wondered, \n",
      ", as, he, continued, to, wait, for, Marta, to, appear, with, the, pets, ., \n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "text = \"\"\"\n",
    "Dave watched as the forest burned up on the hill,\n",
    "only a few miles from his house. The car had\n",
    "been hastily packed and Marta was inside trying to round\n",
    "up the last of the pets. \"Where could she be?\" he wondered\n",
    "as he continued to wait for Marta to appear with the pets.\n",
    "\"\"\"\n",
    "\n",
    "doc = nlp(text)\n",
    "token_list = [token for token in doc]\n",
    "\n",
    "print(token_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ea6750d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      ", Dave, watched, forest, burned, hill, ,, \n",
      ", miles, house, ., car, \n",
      ", hastily, packed, Marta, inside, trying, round, \n",
      ", pets, ., \", ?, \", wondered, \n",
      ", continued, wait, Marta, appear, pets, ., \n",
      "]\n"
     ]
    }
   ],
   "source": [
    "filtered_tokens = [token for token in doc if not token.is_stop]\n",
    "print(filtered_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1999a8d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Token: \\n, lemma: \\n', 'Token: Dave, lemma: Dave', 'Token: watched, lemma: watch', 'Token: forest, lemma: forest', 'Token: burned, lemma: burn', 'Token: hill, lemma: hill', 'Token: ,, lemma: ,', 'Token: \\n, lemma: \\n', 'Token: miles, lemma: mile', 'Token: house, lemma: house', 'Token: ., lemma: .', 'Token: car, lemma: car', 'Token: \\n, lemma: \\n', 'Token: hastily, lemma: hastily', 'Token: packed, lemma: pack', 'Token: Marta, lemma: Marta', 'Token: inside, lemma: inside', 'Token: trying, lemma: try', 'Token: round, lemma: round', 'Token: \\n, lemma: \\n', 'Token: pets, lemma: pet', 'Token: ., lemma: .', 'Token: \", lemma: \"', 'Token: ?, lemma: ?', 'Token: \", lemma: \"', 'Token: wondered, lemma: wonder', 'Token: \\n, lemma: \\n', 'Token: continued, lemma: continue', 'Token: wait, lemma: wait', 'Token: Marta, lemma: Marta', 'Token: appear, lemma: appear', 'Token: pets, lemma: pet', 'Token: ., lemma: .', 'Token: \\n, lemma: \\n']\n"
     ]
    }
   ],
   "source": [
    "lemmas = [\n",
    "    f\"Token: {token}, lemma: {token.lemma_}\"\n",
    "    for token in filtered_tokens\n",
    "]\n",
    "\n",
    "print(lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f8dd703",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.8371646 ,  1.4529226 , -1.6147211 ,  0.678362  , -0.6594443 ,\n",
       "        1.6417935 ,  0.5796405 ,  2.3021278 , -0.13260496,  0.5750932 ,\n",
       "        1.5654886 , -0.6938864 , -0.59607106, -1.5377437 ,  1.9425622 ,\n",
       "       -2.4552505 ,  1.2321601 ,  1.0434952 , -1.5102385 , -0.5787632 ,\n",
       "        0.12055647,  3.6501784 ,  2.6160972 , -0.5710199 , -1.5221789 ,\n",
       "        0.00629176,  0.22760668, -1.922073  , -1.6252862 , -4.226225  ,\n",
       "       -3.495663  , -3.312053  ,  0.81387717, -0.00677544, -0.11603224,\n",
       "        1.4620426 ,  3.0751472 ,  0.35958546, -0.22527039, -2.743926  ,\n",
       "        1.269633  ,  4.606786  ,  0.34034157, -2.1272311 ,  1.2619178 ,\n",
       "       -4.209798  ,  5.452852  ,  1.6940253 , -2.5972986 ,  0.95049495,\n",
       "       -1.910578  , -2.374927  , -1.4227567 , -2.2528825 , -1.799806  ,\n",
       "        1.607501  ,  2.9914255 ,  2.8065152 , -1.2510269 , -0.54964066,\n",
       "       -0.49980402, -1.3882618 , -0.470479  , -2.9670253 ,  1.7884955 ,\n",
       "        4.5282774 , -1.2602427 , -0.14885521,  1.0419178 , -0.08892632,\n",
       "       -1.138275  ,  2.242618  ,  1.5077229 , -1.5030195 ,  2.528098  ,\n",
       "       -1.6761329 ,  0.16694719,  2.123961  ,  0.02546412,  0.38754445,\n",
       "        0.8911977 , -0.07678384, -2.0690763 , -1.1211847 ,  1.4821006 ,\n",
       "        1.1989193 ,  2.1933236 ,  0.5296372 ,  3.0646474 , -1.7223308 ,\n",
       "       -1.3634219 , -0.47471118, -1.7648507 ,  3.565178  , -2.394205  ,\n",
       "       -1.3800384 ], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_tokens[1].vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e5b791b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "\n",
    "fname = 'aclImdb_v1.tar.gz'\n",
    "with tarfile.open(fname, \"r:gz\") as tar:\n",
    "    tar.extractall()\n",
    "    tar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9633e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random                                  \n",
    "\n",
    "def load_training_data(\n",
    "    data_directory: str = \"aclImdb/train\",\n",
    "    split: float = 0.8,\n",
    "    limit: int = 0\n",
    ") -> tuple:\n",
    "    # Загрузка данных из файлов\n",
    "    reviews = []\n",
    "    for label in [\"pos\", \"neg\"]:\n",
    "        labeled_directory = f\"{data_directory}/{label}\"\n",
    "        for review in os.listdir(labeled_directory):\n",
    "            if review.endswith(\".txt\"):\n",
    "                with open(f\"{labeled_directory}/{review}\") as f:\n",
    "                    text = f.read()\n",
    "                    text = text.replace(\"<br />\", \"\\n\\n\")\n",
    "                    if text.strip():\n",
    "                        spacy_label = {\n",
    "                            \"cats\": {\n",
    "                                \"pos\": \"pos\" == label,\n",
    "                                \"neg\": \"neg\" == label}\n",
    "                        }\n",
    "                        reviews.append((text, spacy_label))\n",
    "    random.shuffle(reviews)                    \n",
    "\n",
    "    if limit:                                  \n",
    "        reviews = reviews[:limit]              \n",
    "    split = int(len(reviews) * split)          \n",
    "    return reviews[:split], reviews[split:]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f36835f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"This movie really kicked some ass. I watched it over and over and it never got boring. Angelina Jolie really kicked some ass in the movie, you should see the movie, you won't be disappointed. And another reason you should see the movie is because the guy from The X-Files is in it, David Duchovny.\",\n",
       " {'cats': {'pos': True, 'neg': False}})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_training_data(\n",
    "    data_directory = \"aclImdb/train\",\n",
    "    split = 0.8,\n",
    "    limit = 0)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32868dbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"I'm basing this on my observations of one episode I saw last night (9/27/06). I don't think I'll be watching again. The acting was totally wooden, the plot completely predictable, the ending totally unrealistic -- I mean who would believe a 30 million dollar judgment for the death of a recovering drug addict with terminal cancer? The lead actor (Victor Garber) seemed so uncomfortable, almost embarrassed in his role -- perhaps he realized how bad the writing was!! I fully realize that the drama offered this season is pretty poor, but they can surely find better writers. Maybe they are outsourcing the writing to India or China!! I'll bet we won't be seeing this one next season!\",\n",
       " {'cats': {'pos': False, 'neg': True}})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_training_data(\n",
    "    data_directory = \"aclImdb/train\",\n",
    "    split = 0.8,\n",
    "    limit = 0)[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a02b1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(tokenizer, textcat, test_data: list) -> dict:\n",
    "    reviews, labels = zip(*test_data)\n",
    "    reviews = (tokenizer(review) for review in reviews)\n",
    "    # Указываем TP как малое число, чтобы в знаменателе не оказался 0\n",
    "    TP, FP, TN, FN = 1e-8, 0, 0, 0\n",
    "    for i, review in enumerate(textcat.pipe(reviews)):\n",
    "        true_label = labels[i]['cats']\n",
    "        score_pos = review.cats['pos'] \n",
    "        if true_label['pos']:\n",
    "            if score_pos >= 0.5:\n",
    "                TP += 1\n",
    "            else:\n",
    "                FN += 1\n",
    "        else:\n",
    "            if score_pos >= 0.5:\n",
    "                FP += 1\n",
    "            else:\n",
    "                TN += 1    \n",
    "    precision = TP / (TP + FP)\n",
    "    recall = TP / (TP + FN)\n",
    "    f_score = 2 * precision * recall / (precision + recall)\n",
    "    return {\"precision\": precision, \"recall\": recall, \"f-score\": f_score}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f11a06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import spacy\n",
    "from spacy.util import minibatch, compounding\n",
    "\n",
    "def train_model(\n",
    "    training_data: list,\n",
    "    test_data: list,\n",
    "    iterations: int = 20) -> None:\n",
    "    # Строим конвейер\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    if \"textcat\" not in nlp.pipe_names:\n",
    "        textcat = nlp.create_pipe(\n",
    "            \"textcat\", config={\"architecture\": \"simple_cnn\"}\n",
    "        )\n",
    "        nlp.add_pipe(textcat, last=True)\n",
    "    else:\n",
    "        textcat = nlp.get_pipe(\"textcat\")\n",
    "\n",
    "    textcat.add_label(\"pos\")\n",
    "    textcat.add_label(\"neg\")\n",
    "\n",
    "    # Обучаем только textcat\n",
    "    training_excluded_pipes = [\n",
    "        pipe for pipe in nlp.pipe_names if pipe != \"textcat\"\n",
    "    ]\n",
    "    with nlp.disable_pipes(training_excluded_pipes):\n",
    "        optimizer = nlp.begin_training()\n",
    "        # Training loop\n",
    "        print(\"Начинаем обучение\")\n",
    "        print(\"Loss\\t\\tPrec.\\tRec.\\tF-score\")          \n",
    "        batch_sizes = compounding(\n",
    "            4.0, 32.0, 1.001\n",
    "        )  # Генератор бесконечной последовательности входных чисел\n",
    "        for i in range(iterations):\n",
    "            loss = {}\n",
    "            random.shuffle(training_data)\n",
    "            batches = minibatch(training_data, size=batch_sizes)\n",
    "            for batch in batches:\n",
    "                text, labels = zip(*batch)\n",
    "                nlp.update(\n",
    "                    text,\n",
    "                    labels,\n",
    "                    drop=0.2,\n",
    "                    sgd=optimizer,\n",
    "                    losses=loss\n",
    "                )\n",
    "            with textcat.model.use_params(optimizer.averages):\n",
    "                evaluation_results = evaluate_model(   \n",
    "                    tokenizer=nlp.tokenizer,           \n",
    "                    textcat=textcat,                   \n",
    "                    test_data=test_data                \n",
    "                )                                      \n",
    "                print(f\"{loss['textcat']:9.6f}\\t\\\n",
    "{evaluation_results['precision']:.3f}\\t\\\n",
    "{evaluation_results['recall']:.3f}\\t\\\n",
    "{evaluation_results['f-score']:.3f}\")\n",
    "                \n",
    "    # Сохраняем модель                                 \n",
    "    with nlp.use_params(optimizer.averages):           \n",
    "        nlp.to_disk(\"model_artifacts\")                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "64770c7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Начинаем обучение\n",
      "Loss\t\tPrec.\tRec.\tF-score\n",
      "15.666554\t0.849\t0.806\t0.827\n",
      " 0.178817\t0.864\t0.820\t0.841\n",
      " 0.082166\t0.861\t0.838\t0.849\n",
      " 0.069845\t0.867\t0.843\t0.855\n",
      " 0.060915\t0.872\t0.849\t0.860\n",
      " 0.051639\t0.871\t0.855\t0.863\n",
      " 0.045242\t0.876\t0.856\t0.866\n",
      " 0.038612\t0.878\t0.864\t0.871\n",
      " 0.037759\t0.873\t0.867\t0.870\n",
      " 0.029478\t0.876\t0.869\t0.873\n"
     ]
    }
   ],
   "source": [
    "train, test = load_training_data(limit=20000)\n",
    "train_model(train, test, iterations=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5721cec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_REVIEW = \"\"\"\n",
    "Transcendently beautiful in moments outside the office, it seems almost\n",
    "sitcom-like in those scenes. When Toni Colette walks out and ponders\n",
    "life silently, it's gorgeous.<br /><br />The movie doesn't seem to decide\n",
    "whether it's slapstick, farce, magical realism, or drama, but the best of it\n",
    "doesn't matter. (The worst is sort of tedious - like Office Space with less humor.)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8d1c9f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(input_data: str):\n",
    "    # Загружаем сохраненную модель\n",
    "    loaded_model = spacy.load(\"model_artifacts\")\n",
    "    parsed_text = loaded_model(input_data)\n",
    "    \n",
    "    # Определяем возвращаемое предсказание\n",
    "    if parsed_text.cats[\"pos\"] > parsed_text.cats[\"neg\"]:\n",
    "        prediction = \"Положительный отзыв\"\n",
    "        score = parsed_text.cats[\"pos\"]\n",
    "    else:\n",
    "        prediction = \"Негативный отзыв\"\n",
    "        score = parsed_text.cats[\"neg\"]\n",
    "    print(f\"Текст обзора: {input_data}\\n\\\n",
    "Предсказание: {prediction}\\n\\\n",
    "Score: {score:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5bdd3511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Текст обзора: \n",
      "Transcendently beautiful in moments outside the office, it seems almost\n",
      "sitcom-like in those scenes. When Toni Colette walks out and ponders\n",
      "life silently, it's gorgeous.<br /><br />The movie doesn't seem to decide\n",
      "whether it's slapstick, farce, magical realism, or drama, but the best of it\n",
      "doesn't matter. (The worst is sort of tedious - like Office Space with less humor.)\n",
      "\n",
      "Предсказание: Положительный отзыв\n",
      "Score: 0.909\n"
     ]
    }
   ],
   "source": [
    "test_model(input_data=TEST_REVIEW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d065a889",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
